#!/usr/bin/env bash
set -euo pipefail

# ==============================================================================
# 03-app-n8n.sh — OpenKPI n8n module (production, drop-in, repeatable)
#
# Contract:
# - Sources ./00-env.sh (single source of truth backed by /root/open-kpi.env)
# - Uses ./00-lib.sh for log/retry helpers
#
# Guarantees:
# - Uses OPENKPI_NS only (no NS/NS_OPENKPI drift)
# - Reads Postgres superuser creds from: ${OPENKPI_NS}/openkpi-postgres-secret
#   Supports BOTH key schemas:
#     (A) POSTGRES_DB / POSTGRES_USER / POSTGRES_PASSWORD
#     (B) db / username / password / host / port
# - Creates dedicated n8n role+db in shared OpenKPI Postgres (idempotent)
# - Creates/keeps n8n secrets; no rotation unless FORCE_SECRETS=1
# - Creates exactly ONE Certificate: n8n-tls (deletes legacy n8n-cert)
# - Waits for cert Ready=True so nginx never serves fake/wrong cert after install
# - No forced HTTP→HTTPS redirects on ingress (HTTP-01 must work)
# ==============================================================================

HERE="$(cd -- "$(dirname -- "${BASH_SOURCE[0]}")" && pwd)"
# shellcheck source=/dev/null
. "${HERE}/00-env.sh"
# shellcheck source=/dev/null
. "${HERE}/00-lib.sh"

need(){ command -v "$1" >/dev/null 2>&1 || fatal "Missing required command: $1"; }
need kubectl
need curl

log "[03B][n8n] start"

# ------------------------------------------------------------------------------
# Contract values (from 00-env.sh)
# ------------------------------------------------------------------------------
: "${OPENKPI_NS:=open-kpi}"
: "${STORAGE_CLASS:=local-path}"
: "${TLS_MODE:=per-host-http01}"            # off|per-host-http01
: "${INGRESS_CLASS:=nginx}"                 # nginx|traefik
: "${CERT_CLUSTER_ISSUER:=letsencrypt-http01}"
: "${N8N_HOST:?missing N8N_HOST}"

# Generated by 00-env.sh and persisted in /root/open-kpi.env
: "${N8N_PASS:?missing N8N_PASS}"
: "${N8N_ENCRYPTION_KEY:?missing N8N_ENCRYPTION_KEY}"

# Optional user override (kept stable)
: "${N8N_USER:=admin}"

FORCE_SECRETS="${FORCE_SECRETS:-0}"

# ------------------------------------------------------------------------------
# Module constants
# ------------------------------------------------------------------------------
NS_N8N="n8n"
APP_NAME="n8n"
SVC_NAME="n8n"
ING_NAME="n8n"

TLS_SECRET="n8n-tls"
CERT_NAME="n8n-tls"

PVC_NAME="n8n-data"

DB_SECRET="n8n-db-secret"
APP_SECRET="n8n-secret"
N8N_DB_NAME="${N8N_DB_NAME:-n8n}"
N8N_DB_USER="${N8N_DB_USER:-n8n}"

# ------------------------------------------------------------------------------
# Helpers
# ------------------------------------------------------------------------------
rand_b64url(){
  if command -v openssl >/dev/null 2>&1; then
    openssl rand -base64 24 | tr -d '\n' | tr '+/' '-_' | tr -d '='
  else
    head -c 24 /dev/urandom | base64 2>/dev/null | tr -d '\n' | tr '+/' '-_' | tr -d '='
  fi
}

b64key(){
  local ns="$1" secret="$2" key="$3"
  kubectl -n "$ns" get secret "$secret" -o "jsonpath={.data.${key}}" 2>/dev/null | base64 -d 2>/dev/null || true
}

# ------------------------------------------------------------------------------
# Ensure namespace
# ------------------------------------------------------------------------------
log "[03B][n8n] ensure namespace: ${NS_N8N}"
ensure_ns "${NS_N8N}"

# ------------------------------------------------------------------------------
# Read shared Postgres creds from OpenKPI namespace secret (supports both schemas)
# ------------------------------------------------------------------------------
log "[03B][n8n] read Postgres superuser creds from ${OPENKPI_NS}/openkpi-postgres-secret"

PG_SUPER_DB="$(b64key "${OPENKPI_NS}" "openkpi-postgres-secret" "POSTGRES_DB")"
PG_SUPER_USER="$(b64key "${OPENKPI_NS}" "openkpi-postgres-secret" "POSTGRES_USER")"
PG_SUPER_PASS="$(b64key "${OPENKPI_NS}" "openkpi-postgres-secret" "POSTGRES_PASSWORD")"

# fallback to legacy schema keys currently in your cluster
if [[ -z "${PG_SUPER_DB}" ]]; then PG_SUPER_DB="$(b64key "${OPENKPI_NS}" "openkpi-postgres-secret" "db")"; fi
if [[ -z "${PG_SUPER_USER}" ]]; then PG_SUPER_USER="$(b64key "${OPENKPI_NS}" "openkpi-postgres-secret" "username")"; fi
if [[ -z "${PG_SUPER_PASS}" ]]; then PG_SUPER_PASS="$(b64key "${OPENKPI_NS}" "openkpi-postgres-secret" "password")"; fi

PG_HOST="$(b64key "${OPENKPI_NS}" "openkpi-postgres-secret" "host")"
PG_PORT="$(b64key "${OPENKPI_NS}" "openkpi-postgres-secret" "port")"

# derive stable in-cluster host/port when not present in secret
: "${PG_HOST:=openkpi-postgres.${OPENKPI_NS}.svc.cluster.local}"
: "${PG_PORT:=5432}"

if [[ -z "${PG_SUPER_DB}" || -z "${PG_SUPER_USER}" || -z "${PG_SUPER_PASS}" ]]; then
  warn "[03B][n8n] openkpi-postgres-secret keys present (names only)"
  kubectl -n "${OPENKPI_NS}" get secret openkpi-postgres-secret -o jsonpath='{.data}' 2>/dev/null | head -c 500 || true
  echo >&2
  fatal "Missing Postgres creds in ${OPENKPI_NS}/openkpi-postgres-secret. Expected POSTGRES_* or legacy db/username/password."
fi

# ------------------------------------------------------------------------------
# Ensure n8n DB secret (no overwrite unless FORCE_SECRETS=1)
# ------------------------------------------------------------------------------
log "[03B][n8n] ensure ${DB_SECRET} (FORCE_SECRETS=${FORCE_SECRETS})"
if kubectl -n "${NS_N8N}" get secret "${DB_SECRET}" >/dev/null 2>&1; then
  if [[ "${FORCE_SECRETS}" == "1" ]]; then
    kubectl -n "${NS_N8N}" delete secret "${DB_SECRET}" >/dev/null 2>&1 || true
  fi
fi

if ! kubectl -n "${NS_N8N}" get secret "${DB_SECRET}" >/dev/null 2>&1; then
  N8N_DB_PASSWORD="$(rand_b64url)"
  kubectl -n "${NS_N8N}" create secret generic "${DB_SECRET}" \
    --from-literal=DB_NAME="${N8N_DB_NAME}" \
    --from-literal=DB_USER="${N8N_DB_USER}" \
    --from-literal=DB_PASSWORD="${N8N_DB_PASSWORD}" \
    --dry-run=client -o yaml | kubectl -n "${NS_N8N}" apply -f - >/dev/null
fi

N8N_DB_PASSWORD="$(b64key "${NS_N8N}" "${DB_SECRET}" "DB_PASSWORD")"

# ------------------------------------------------------------------------------
# Bootstrap role+db in shared Postgres (POSIX sh; idempotent)
# ------------------------------------------------------------------------------
log "[03B][n8n] bootstrap role+db in shared Postgres (${PG_HOST}:${PG_PORT})"

kubectl -n "${NS_N8N}" delete pod n8n-pg-bootstrap --ignore-not-found >/dev/null 2>&1 || true

kubectl -n "${NS_N8N}" run n8n-pg-bootstrap \
  --image=postgres:16 \
  --restart=Never \
  --env="PGHOST=${PG_HOST}" \
  --env="PGPORT=${PG_PORT}" \
  --env="PGDATABASE=${PG_SUPER_DB}" \
  --env="PGUSER=${PG_SUPER_USER}" \
  --env="PGPASSWORD=${PG_SUPER_PASS}" \
  --command -- sh -lc "
    set -eu

    echo '[BOOT] ensure role ${N8N_DB_USER}'
    if psql -tAc \"SELECT 1 FROM pg_roles WHERE rolname='${N8N_DB_USER}'\" | grep -q 1; then
      echo '[BOOT] role exists'
    else
      echo '[BOOT] creating role'
      psql -v ON_ERROR_STOP=1 -c \"CREATE USER \\\"${N8N_DB_USER}\\\" WITH PASSWORD '${N8N_DB_PASSWORD}';\"
    fi

    echo '[BOOT] ensure db ${N8N_DB_NAME}'
    if psql -tAc \"SELECT 1 FROM pg_database WHERE datname='${N8N_DB_NAME}'\" | grep -q 1; then
      echo '[BOOT] db exists'
    else
      echo '[BOOT] creating db'
      psql -v ON_ERROR_STOP=1 -c \"CREATE DATABASE \\\"${N8N_DB_NAME}\\\" OWNER \\\"${N8N_DB_USER}\\\";\"
    fi

    echo '[BOOT] ensure owner is correct'
    psql -v ON_ERROR_STOP=1 -c \"ALTER DATABASE \\\"${N8N_DB_NAME}\\\" OWNER TO \\\"${N8N_DB_USER}\\\";\"

    echo '[BOOT] grant privileges'
    psql -v ON_ERROR_STOP=1 -c \"GRANT ALL PRIVILEGES ON DATABASE \\\"${N8N_DB_NAME}\\\" TO \\\"${N8N_DB_USER}\\\";\"
  " >/dev/null

kubectl -n "${NS_N8N}" wait --for=condition=Ready pod/n8n-pg-bootstrap --timeout=180s >/dev/null 2>&1 || true
kubectl -n "${NS_N8N}" logs pod/n8n-pg-bootstrap --tail=250 || true
kubectl -n "${NS_N8N}" delete pod n8n-pg-bootstrap --ignore-not-found >/dev/null 2>&1 || true

# ------------------------------------------------------------------------------
# Ensure n8n app secret (basic auth + encryption key)
# ------------------------------------------------------------------------------
log "[03B][n8n] ensure ${APP_SECRET} (FORCE_SECRETS=${FORCE_SECRETS})"
if kubectl -n "${NS_N8N}" get secret "${APP_SECRET}" >/dev/null 2>&1; then
  if [[ "${FORCE_SECRETS}" == "1" ]]; then
    kubectl -n "${NS_N8N}" delete secret "${APP_SECRET}" >/dev/null 2>&1 || true
  fi
fi

if ! kubectl -n "${NS_N8N}" get secret "${APP_SECRET}" >/dev/null 2>&1; then
  kubectl -n "${NS_N8N}" create secret generic "${APP_SECRET}" \
    --from-literal=N8N_USER="${N8N_USER}" \
    --from-literal=N8N_PASS="${N8N_PASS}" \
    --from-literal=N8N_ENCRYPTION_KEY="${N8N_ENCRYPTION_KEY}" \
    --dry-run=client -o yaml | kubectl -n "${NS_N8N}" apply -f - >/dev/null
fi

# ------------------------------------------------------------------------------
# PVC + Deployment + Service
# ------------------------------------------------------------------------------
log "[03B][n8n] apply pvc/deploy/svc"
kubectl -n "${NS_N8N}" apply -f - <<YAML >/dev/null
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: ${PVC_NAME}
spec:
  accessModes: ["ReadWriteOnce"]
  storageClassName: ${STORAGE_CLASS}
  resources:
    requests:
      storage: 5Gi
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ${APP_NAME}
spec:
  replicas: 1
  selector:
    matchLabels:
      app: ${APP_NAME}
  template:
    metadata:
      labels:
        app: ${APP_NAME}
    spec:
      securityContext:
        fsGroup: 1000
      containers:
      - name: n8n
        image: n8nio/n8n:latest
        ports:
        - name: http
          containerPort: 5678
        env:
        - name: N8N_PROTOCOL
          value: "https"
        - name: N8N_HOST
          value: "${N8N_HOST}"
        - name: WEBHOOK_URL
          value: "https://${N8N_HOST}/"
        - name: N8N_PORT
          value: "5678"

        - name: N8N_ENCRYPTION_KEY
          valueFrom:
            secretKeyRef:
              name: ${APP_SECRET}
              key: N8N_ENCRYPTION_KEY
        - name: N8N_BASIC_AUTH_ACTIVE
          value: "true"
        - name: N8N_BASIC_AUTH_USER
          valueFrom:
            secretKeyRef:
              name: ${APP_SECRET}
              key: N8N_USER
        - name: N8N_BASIC_AUTH_PASSWORD
          valueFrom:
            secretKeyRef:
              name: ${APP_SECRET}
              key: N8N_PASS

        - name: DB_TYPE
          value: "postgresdb"
        - name: DB_POSTGRESDB_HOST
          value: "${PG_HOST}"
        - name: DB_POSTGRESDB_PORT
          value: "${PG_PORT}"
        - name: DB_POSTGRESDB_DATABASE
          valueFrom:
            secretKeyRef:
              name: ${DB_SECRET}
              key: DB_NAME
        - name: DB_POSTGRESDB_USER
          valueFrom:
            secretKeyRef:
              name: ${DB_SECRET}
              key: DB_USER
        - name: DB_POSTGRESDB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: ${DB_SECRET}
              key: DB_PASSWORD

        volumeMounts:
        - name: n8n-data
          mountPath: /home/node/.n8n
        readinessProbe:
          httpGet:
            path: /
            port: 5678
          initialDelaySeconds: 10
          periodSeconds: 5
          timeoutSeconds: 3
          failureThreshold: 24
        livenessProbe:
          httpGet:
            path: /
            port: 5678
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 3
          failureThreshold: 12
      volumes:
      - name: n8n-data
        persistentVolumeClaim:
          claimName: ${PVC_NAME}
---
apiVersion: v1
kind: Service
metadata:
  name: ${SVC_NAME}
spec:
  type: ClusterIP
  selector:
    app: ${APP_NAME}
  ports:
  - name: http
    port: 80
    targetPort: 5678
YAML

kubectl -n "${NS_N8N}" rollout status deploy/${APP_NAME} --timeout=600s

# ------------------------------------------------------------------------------
# Ingress + TLS
# ------------------------------------------------------------------------------
log "[03B][n8n] apply ingress"
kubectl -n "${NS_N8N}" apply -f - <<YAML >/dev/null
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ${ING_NAME}
  annotations:
    cert-manager.io/cluster-issuer: "${CERT_CLUSTER_ISSUER}"
spec:
  ingressClassName: "${INGRESS_CLASS}"
  tls:
  - hosts:
    - "${N8N_HOST}"
    secretName: ${TLS_SECRET}
  rules:
  - host: "${N8N_HOST}"
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: ${SVC_NAME}
            port:
              number: 80
YAML

# Ensure ONE Certificate only (delete legacy duplicates)
kubectl -n "${NS_N8N}" delete certificate n8n-cert --ignore-not-found >/dev/null 2>&1 || true

if [[ "${TLS_MODE}" == "per-host-http01" ]]; then
  log "[03B][n8n] apply certificate (one cert only)"
  kubectl -n "${NS_N8N}" apply -f - <<YAML >/dev/null
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: ${CERT_NAME}
spec:
  secretName: ${TLS_SECRET}
  issuerRef:
    name: ${CERT_CLUSTER_ISSUER}
    kind: ClusterIssuer
  dnsNames:
  - "${N8N_HOST}"
YAML

  log "[03B][n8n] wait certificate Ready=True"
  kubectl -n "${NS_N8N}" wait --for=condition=Ready "certificate/${CERT_NAME}" --timeout=15m >/dev/null
  kubectl -n "${NS_N8N}" get secret "${TLS_SECRET}" >/dev/null
else
  log "[03B][n8n] TLS_MODE=${TLS_MODE}; skipping Certificate creation"
fi

# ------------------------------------------------------------------------------
# Sanity
# ------------------------------------------------------------------------------
log "[03B][n8n] sanity: service endpoints"
kubectl -n "${NS_N8N}" get svc "${SVC_NAME}" -o wide
kubectl -n "${NS_N8N}" get endpoints "${SVC_NAME}" -o wide || true
log "[03B][n8n] ready: https://${N8N_HOST}/"
log "[03B][n8n] done"
